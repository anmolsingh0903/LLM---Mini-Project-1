# 🧠 Basics of NLP: Text Cleaning & Vectorization
## 📌 Project Overview

This project focuses on the fundamentals of Natural Language Processing (NLP), specifically text preprocessing and vectorization techniques. It demonstrates how to clean, process, and convert textual data into numerical representations for machine learning models. The project also evaluates different approaches like Bag of Words, TF-IDF, and applies classification algorithms to analyze text.

## 🚀 Features

### **Text Cleaning:**
- Removing unwanted characters, stopwords, punctuation, and performing stemming & lemmatization.

### **Text Vectorization:**

- Count Vectorizer

- TF-IDF Vectorizer

### **Machine Learning Models:**

- Naive Bayes (MultinomialNB)

- Random Forest Classifier

### **Model Evaluation:**

- Accuracy Score

- Confusion Matrix

- Classification Report

## 🛠️ Tech Stack

### Programming Language: Python 3
### **Libraries & Tools:**

- NLTK → Stopwords, Stemming, Lemmatization, WordNet

- Scikit-learn → Vectorization, Model Building, Evaluation Metrics

- Pandas & NumPy → Data Handling

- Matplotlib / Seaborn → Visualization

## **📊 Results**

- Implemented and compared Count Vectorizer and TF-IDF.

- Achieved model evaluation using accuracy, precision, recall, and F1-score.

- Visualized performance using confusion matrices and plots.

## **🧩 Future Enhancements**

- Integration of word embeddings (Word2Vec, GloVe).
